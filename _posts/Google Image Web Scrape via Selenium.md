<h1> Google Image Web Scrape via Selenium </h1>

Knowing how to develop data for image classification projects can be extremely helpful in cases where there is no data available or if available data is limited. 
In my own case, I needed to retrieve images of various dog breeds to create my own dataset. To do so, I leveraged a package called [Selenium](https://selenium-python.readthedocs.io/installation.html#introduction)
, which allows individuals to control web browsers through python code. 

Before we can begin executing commands, we need to decide which browser we want to control and install the relevant web driver. See [here](https://selenium-python.readthedocs.io/installation.html#drivers)
for more details. We’ll use Google Chrome for this example. With web drivers, we can set certain parameters (or options) to control some basic aspects of our 
webdriver. One of the most helpful options to enable is “headless”. This prevents a browser window opening and instead executes browser commands in the background.
Example code below:

```
  options = webdriver.ChromeOptions() 
  options.add_argument('--headless')
```
Once you’re options are set, you can initialize your webdriver as shown below:

```
chrome_driver_path = './chromedriver'
driver = webdriver.Chrome(executable_path=chrome_driver_path, options=options)
```

Now comes the fun part! We can send our driver to Google images by calling `driver.get('http://www.images.google.com/')`. 
If we want the driver to click on a specific element of the page, in our case the search box, we need to determine how the element is being defined. 
This is easily done through right-clicking on the target and choosing Inspect from the menu. Doing so will reveal the page’s code. In this instance, 
we’ll call the search box by its name (“q”).

```
search_box = driver.find_element_by_name('q')
```

To actually search, we’ll call on .send_keys():

```
search_for = dog_breed
search_box.send_keys(search_for)
search_box.submit()
```

Because we’re using Selenium to scrape the web for images, we need some code that will scroll to the bottom of the page, click the “Show More Results” button when 
it appears in order to keep scrolling through all of the results, screenshot each image on the page and name the resulting file generated by the screenshot. See 
below for a formula that will do all of this once a search term, web driver path, destination folder path for the screenshot images and the number of desired images
is provided. This formula includes a few other web driver options to optimize for better quality images. 

```
#Defining formula for searching google images and saving n images

def save_dog_pictures(chrome_driver_path,dog_breed,final_path,n):

    #path for chrome driver
    chrome_driver_path = chrome_driver_path

    #Headless aka no browser window

    options = webdriver.ChromeOptions() 
    options.add_argument('--headless')
    options.add_argument("--window-size=1920x1080")
    options.add_argument('--start-maximized')
    options.add_argument("--ignore-certificate-errors");


    #defining driver using path
    driver = webdriver.Chrome(executable_path=chrome_driver_path, options=options)

    #Navigating to google images

    driver.get('http://www.images.google.com/')

    #Identifying the search box on the page 

    search_box = driver.find_element_by_name('q')

    #Searching for relevant query

    search_for = dog_breed
    search_box.send_keys(search_for)
    search_box.submit()
    
    #Scrolling to the bottom of the page. Otherwise, n will be limited
    
    last_height = driver.execute_script('return document.body.scrollHeight')


    while True:
        #Tells the page to scroll all the way to the bottom
        driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')
        #Stops the program for 2 seconds
        time.sleep(2)
        #Returns the height of the page after the driver scrolls down
        new_height = driver.execute_script('return document.body.scrollHeight')
        #This part will click the "Show more results" button when it pops up
        try:
            driver.find_element_by_xpath('//*[@id="islmp"]/div/div/div/div/div[4]/div[2]/input').click()
            time.sleep(2)
        except:
            pass
        #If the returned height is the same as the one found on line 28 the loop stops cause it means we couldn't scroll anymore
        if new_height == last_height:
            break
        last_height = new_height

    #Saving first n images

    for i in range(1, (n+1)):
        try:
            driver.find_element_by_xpath('//*[@id="islrg"]/div[1]/div['+str(i)+']/a[1]/div[1]/img').screenshot(
                final_path+search_for.replace(" ","_")+'_'+str(i)+'.png')
        except:
            pass
```

And there you have it! Images downloaded to your computer and a dataset ready to use. 
When working with multiple search terms, we can also use the formula within a for loop to speed up some of our work. 


